{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casjunior93/Desafio-DIO-Sistema-de-Recomendacao-por-Imagens-Digitais/blob/main/Sistema_de_Recomenda%C3%A7%C3%A3o_por_Imagens_Digitais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI6a3aq4ls31"
      },
      "source": [
        "# Criando um Sistema de Recomendação por Imagens Digitais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oon2FEulwgC"
      },
      "source": [
        "## Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bc-Os2-6lRLo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from shutil import move\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm1k0lLXmw0E"
      },
      "source": [
        "## Habiltando Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkiaQttlm1h-",
        "outputId": "ec61546a-35e5-4db4-f7a3-d283fd44c8d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGv9pXiZma4S"
      },
      "source": [
        "## Importando biblioteca do Kaggle e minhas credenciais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1gB69Pol1fV",
        "outputId": "db4964ba-9152-49ff-f896-be692f1df436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.13.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.13-py3-none-any.whl size=77733 sha256=65af46641ad4270fd26740a5d7ce8760cc7d363dbf9a9be54d7137adae26c268\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/45/15/6d6d116cd2539fb8f450d64b0aee4a480e5366bb11b42ac763\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.13\n",
            "    Uninstalling kaggle-1.5.13:\n",
            "      Successfully uninstalled kaggle-1.5.13\n",
            "Successfully installed kaggle-1.5.13\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U kaggle\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgGBOuQtnC7T"
      },
      "source": [
        "## Obtendo os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTMgIl2tnEpW"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d paramaggarwal/fashion-product-images-small\n",
        "!unzip fashion-product-images-small.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-CDTFY9nFP4",
        "outputId": "b8547d26-0764-43ba-b9ff-60f8d32e50fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44441/44441 [02:35<00:00, 285.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moved 44441 images.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "os.mkdir('/content/Fashion_data')\n",
        "os.chdir('/content/Fashion_data')\n",
        "\n",
        "df = pd.read_csv('/content/styles.csv', usecols=['id','masterCategory']).reset_index()\n",
        "df['id'] = df['id'].astype('str')\n",
        "\n",
        "all_images = os.listdir('/content/images/')\n",
        "co = 0\n",
        "os.mkdir('/content/Fashion_data/categories')\n",
        "for image in tqdm(all_images):\n",
        "    category = df[df['id'] == image.split('.')[0]]['masterCategory']\n",
        "    category = str(list(category)[0])\n",
        "    if not os.path.exists(os.path.join('/content/Fashion_data/categories', category)):\n",
        "        os.mkdir(os.path.join('/content/Fashion_data/categories', category))\n",
        "    path_from = os.path.join('/content/images', image)\n",
        "    path_to = os.path.join('/content/Fashion_data/categories', category, image)\n",
        "    move(path_from, path_to)\n",
        "    co += 1\n",
        "print('Moved {} images.'.format(co))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH5h3-Avokfy"
      },
      "source": [
        "## Transferência de aprendizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnvfDlIeosFO"
      },
      "source": [
        "Baixando o modelo de imagem pré-treinado e adicionando duas camadas adicionais: a primeira camada é uma camada de vetor de recursos e a segunda camada é a camada de classificação. Vamos treinar apenas essas 2 camadas em nossos dados e, após o treinamento, selecionaremos a camada de vetor de recursos como saída de nosso codificador ajustado. Depois de ajustar o modelo, salvaremos o extrator de recursos para uso posterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5gid_q1nXTc",
        "outputId": "573ee367-f12c-4856-ece8-9e69786acc51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF version: 2.12.0\n",
            "Hub version: 0.13.0\n",
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wPArKTeo408",
        "outputId": "be71255d-c925-4e83-81b6-88a0240cb7f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using https://tfhub.dev/google/bit/m-r50x3/1 with input size (224, 224)\n"
          ]
        }
      ],
      "source": [
        "MODULE_HANDLE = 'https://tfhub.dev/google/bit/m-r50x3/1'\n",
        "IMAGE_SIZE = (224, 224)\n",
        "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n",
        "BATCH_SIZE = 32 \n",
        "N_FEATURES = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEb8bzijqT0A"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/Fashion_data/categories'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZSN4SAMqW4Y",
        "outputId": "b476a411-ab5f-47a1-f7b8-3ed0ed00a925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8886 images belonging to 7 classes.\n",
            "Found 35555 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
        "                   interpolation=\"bilinear\")\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    **datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
        "\n",
        "do_data_augmentation = False \n",
        "if do_data_augmentation:\n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      horizontal_flip=True,\n",
        "      width_shift_range=0.2, height_shift_range=0.2,\n",
        "      shear_range=0.2, zoom_range=0.2,\n",
        "      **datagen_kwargs)\n",
        "else:\n",
        "  train_datagen = valid_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-Z17ZQFqe2y"
      },
      "source": [
        "Construindo o modelo com Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOsyeqdWqbOm",
        "outputId": "1c5ea4b6-7f89-4dda-83a6-5ba5183c8d87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building model with https://tfhub.dev/google/bit/m-r50x3/1\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 6144)              211174080 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 6144)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1573120   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,748,999\n",
            "Trainable params: 1,574,919\n",
            "Non-trainable params: 211,174,080\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "    hub.KerasLayer(MODULE_HANDLE, trainable=False),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(N_FEATURES,\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes,\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "])\n",
        "model.build((None,)+IMAGE_SIZE+(3,))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEgLyKpmqmPf"
      },
      "source": [
        "Compilando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5zS3IPMqhdV"
      },
      "outputs": [],
      "source": [
        "# Define optimiser and loss\n",
        "lr = 0.003 * BATCH_SIZE / 512 \n",
        "SCHEDULE_LENGTH = 500\n",
        "SCHEDULE_BOUNDARIES = [200, 300, 400]\n",
        "\n",
        "# Decay learning rate by a factor of 10 at SCHEDULE_BOUNDARIES.\n",
        "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=SCHEDULE_BOUNDARIES, \n",
        "                                                                   values=[lr, lr*0.1, lr*0.001, lr*0.0001])\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF3pYuOrqvDR"
      },
      "source": [
        "Treinando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzVwiUgcqoXh",
        "outputId": "78c45c4b-f6ab-4971-897b-b4a35be53ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1111/1111 [==============================] - 1250s 1s/step - loss: 0.2430 - accuracy: 0.9697 - val_loss: 0.1272 - val_accuracy: 0.9896\n"
          ]
        }
      ],
      "source": [
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5, steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=validation_steps).history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQXvqFqUq3Cc"
      },
      "source": [
        "Perda e acurácia durante o treinamento do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y630wGnZqwqW"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"accuracy\"])\n",
        "plt.plot(hist[\"val_accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ludaJo_jrDjr"
      },
      "source": [
        "Salvando o modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po4kxlLSq7Pp"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('/content/drive/MyDrive/ImgSim/'):\n",
        "    os.mkdir('/content/drive/MyDrive/ImgSim/')\n",
        "\n",
        "feature_extractor = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-3].output)\n",
        "feature_extractor.save('/content/drive/MyDrive/ImgSim/bit_feature_extractor', save_format='tf')\n",
        "\n",
        "saved_model_path = '/content/drive/MyDrive/ImgSim/bit_model'\n",
        "tf.saved_model.save(model, saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dca5YvzarFsn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOW72q9qfiuB0WHZhZVFs7",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}